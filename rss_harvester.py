# rss_harvester.py
import feedparser
from datetime import datetime
import hashlib
import json

FEEDS = [
    "https://news.samsung.com/global/feed",
    "https://news.google.com/rss/search?q=ì‚¼ì„±ì „ì+when:1d&hl=ko&gl=KR&ceid=KR:ko",
    "https://www.yna.co.kr/rss/all.xml",
    "https://www.hani.co.kr/rss/",
    "http://www.chosun.com/site/data/rss/rss.xml",
    "https://rss.mt.co.kr/rss/news.xml",
    "https://rss.etnews.com/ETnews.xml"
]

def make_id(entry):
    base = (entry.get("title") or "") + (entry.get("link") or "") + (entry.get("published", "") or "")
    return hashlib.sha256(base.encode("utf-8")).hexdigest()

def harvest():
    collected = []
    for feed_url in FEEDS:
        print(f"ğŸ“¡ í”¼ë“œ ìˆ˜ì§‘ ì¤‘: {feed_url}")
        parsed = feedparser.parse(feed_url)
        for entry in parsed.entries:
            print("ğŸ“° ìˆ˜ì§‘í•œ ê¸°ì‚¬:", entry.get("title", "ì œëª© ì—†ìŒ"))
            item = {
                "id": make_id(entry),
                "feed": feed_url,
                "title": entry.get("title"),
                "link": entry.get("link"),
                "summary": entry.get("summary", ""),
                "published": entry.get("published", ""),
                "collected_at": datetime.utcnow().isoformat()
            }
            collected.append(item)
    return collected

if __name__ == "__main__":
    print("ğŸ” RSS ìˆ˜ì§‘ ì‹œì‘")
    results = harvest()
    print(f"âœ… ì´ {len(results)}ê°œ ìˆ˜ì§‘ë¨.")
    with open("rss_output.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
